{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AnimeGM - Autoencoder\n",
    "GOAL: Generate new anime-style images\n",
    "    \n",
    "Methodology:\n",
    "1. Build a dataset of images suitable for out needs\n",
    "2. Build a generative model.\n",
    "3. Train the model\n",
    "4. Generate a new image with random numbers\n",
    "5. Transfer style to a photo\n",
    "6. Examine results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Build a dataset\n",
    "Pull in an existing dataset and modify it for my needs.\n",
    "\n",
    "Lets start with the danbooru 2017 anime image dataset. Now this dataset is huge. So we are only going to use 1 torrent of the SFW subset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import misc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import color\n",
    "import seaborn as sns; sns.set()\n",
    "from skimage.transform import resize\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from skimage import data\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.ops import reset_default_graph\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gray_scale_resize(image, resize_dim):\n",
    "    # convert image to grayscale\n",
    "    # same computation while we experiment\n",
    "    gray_image = color.rgb2gray(image)\n",
    "    \n",
    "    # Resize the image down to 128x128\n",
    "    resized_image = resize(gray_image, (resize_dim, resize_dim))\n",
    "    \n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_images(paths_list, n_images, resize_dim):\n",
    "    # slice paths list to the amount we want\n",
    "    slice_paths_list = paths_list[:n_images]\n",
    "\n",
    "    # create an array for images\n",
    "    images = np.zeros((n_images, resize_dim, resize_dim), dtype=np.float32)\n",
    "        \n",
    "    for i, image_path in enumerate(slice_paths_list): \n",
    "        # read image\n",
    "        image = misc.imread(join(path, image_path))\n",
    "\n",
    "        # rescale image\n",
    "        images[i] = gray_scale_resize(image, resize_dim)\n",
    "        \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_image(image):\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_images(images, figsize=(10, 10)):\n",
    "    # get the number of images\n",
    "    n_images = images.shape[0]\n",
    "    # get the square root of the number of images\n",
    "    squareroot = int(np.ceil(np.sqrt(n_images)))\n",
    "    \n",
    "    fig, ax = plt.subplots(squareroot, squareroot, figsize=figsize,\n",
    "                           subplot_kw=dict(xticks=[], yticks=[]))\n",
    "    fig.subplots_adjust(hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for i, axi in enumerate(ax.flat):\n",
    "        # exit if the index of subplots is greater than amount of images\n",
    "        if i >= n_images:\n",
    "            return\n",
    "        im = axi.imshow(images[i], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(batch_size, images):\n",
    "    np.random.RandomState(0)\n",
    "    \n",
    "    # get shape of images\n",
    "    images_shape = images.shape\n",
    "    \n",
    "    # create a range based on number of images\n",
    "    images_range = np.arange(0, images_shape[0])\n",
    "    \n",
    "    # pick n batch_size random elements from images range\n",
    "    random_indices = np.random.choice(images_range, batch_size, replace=False)\n",
    "    \n",
    "    # use random indices to grab a batch from images\n",
    "    random_elements = images[random_indices]\n",
    "    \n",
    "    return random_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the normalized image\n",
    "def preprocess(images, mean_image, std_dev_image):\n",
    "    norm_image = (images - mean_image) / std_dev_image\n",
    "    return norm_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove normalization\n",
    "def deprocess(norm_image, mean_image, std_dev_image):\n",
    "    denorm_image =  (norm_image * std_dev_image) + mean_image\n",
    "    return denorm_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# base path\n",
    "path = 'danbooru-small'\n",
    "\n",
    "# list of img paths\n",
    "paths_list = listdir(path)\n",
    "\n",
    "# number of image to use in dataset\n",
    "n_images = 1000\n",
    "\n",
    "# number of pixels to resize image to\n",
    "resize_dim = 64\n",
    "\n",
    "# number of features\n",
    "n_features = resize_dim * resize_dim\n",
    "\n",
    "# hyper parameters~~~~\n",
    "batch_size = 10\n",
    "n_batches = int(n_images / batch_size)\n",
    "n_epochs = 10\n",
    "dimensions = [2048, 1024, 512, 256]\n",
    "\n",
    "# number of test images\n",
    "n_tests = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images\n",
    "images = load_images(paths_list, n_images, resize_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the images of the dataset\n",
    "show_images(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape images \n",
    "reshaped_images = images.reshape(-1, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the mean image of the dataset\n",
    "# minus this from each batch so to normalize them.\n",
    "# this will help the values from going wild\n",
    "mean_image = reshaped_images.mean(axis=0)\n",
    "\n",
    "# flatten it\n",
    "mean_image_reshaped = mean_image.reshape(resize_dim, resize_dim)\n",
    "\n",
    "# inspect it\n",
    "show_image(mean_image_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the standard deviation image\n",
    "std_dev_image = reshaped_images.std(axis=0)\n",
    "\n",
    "# flatten it\n",
    "std_dev_image_reshaped = std_dev_image.reshape(resize_dim, resize_dim)\n",
    "\n",
    "# inspect it\n",
    "show_image(std_dev_image_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test images to reconstruct\n",
    "test_images = reshaped_images[:n_tests]\n",
    "\n",
    "# reshape them\n",
    "reshaped_test_images = test_images.reshape(-1, resize_dim, resize_dim)\n",
    "\n",
    "# plot them\n",
    "show_images(reshaped_test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build a generative model\n",
    "Lets build an autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a place holder for inputs\n",
    "X = tf.placeholder(tf.float32, [None, n_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build the first half of the autoencoder which reduces dimensions at each layer\n",
    "# copy X placeholder to current_input\n",
    "current_input = X\n",
    "n_input = n_features\n",
    "\n",
    "# create a list to store each matrix created\n",
    "Ws = []\n",
    "\n",
    "# loop over the list of dimensions and create a layer\n",
    "# layer_i = index of current element\n",
    "# n_output = element\n",
    "for layer_i, n_output in enumerate(dimensions):\n",
    "    # use variable scope to encapsulate variables\n",
    "    # prefix all variables created in this scope\n",
    "    with tf.variable_scope(\"encoder/layer/{}\".format(layer_i)):\n",
    "        \n",
    "        # create a weight matrix of the shape [n_input, n_output]\n",
    "        W = tf.get_variable(\n",
    "                name='W',\n",
    "                shape=[n_input, n_output],\n",
    "                initializer=tf.random_normal_initializer(mean=0.0, stddev=0.02))\n",
    "        \n",
    "        # create bais vector of the shape [n_output]\n",
    "        b = tf.get_variable(\n",
    "                name='b',\n",
    "                shape=[n_output],\n",
    "                dtype=tf.float32,\n",
    "                initializer=tf.constant_initializer(0.0))\n",
    "        \n",
    "        # multiply the layer input and the weight matrix\n",
    "        # and add the bais\n",
    "        h = tf.nn.bias_add(\n",
    "                name='h',\n",
    "                value=tf.matmul(current_input, W),\n",
    "                bias=b)\n",
    "        \n",
    "        # use an activation function (RELU) on the output and set it to the input for the next layer\n",
    "        current_input = tf.nn.relu(h)\n",
    "        \n",
    "        # store the weight matrix so that we can build the decoder\n",
    "        Ws.append(W)\n",
    "        \n",
    "        # update the input dimensions with the current layer output\n",
    "        n_input = n_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reverse the order of the weight matrices\n",
    "Ws = Ws[::-1]\n",
    "\n",
    "# reverse the order of the dimensions\n",
    "# append on the original dimension on the end of the list\n",
    "dimensions = dimensions[::-1][1:] + [n_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loop over the list of dimensions and create a layer\n",
    "# layer_i = index of current element\n",
    "# n_output = element\n",
    "for layer_i, n_output in enumerate(dimensions):\n",
    "    # use variable scope to encapsulate variables\n",
    "    # prefix all variables created in this scope\n",
    "    with tf.variable_scope(\"decoder/layer/{}\".format(layer_i)):\n",
    "        \n",
    "        # grab the weight matrix fron the encoder and transpose it\n",
    "        W = tf.transpose(Ws[layer_i])\n",
    "        \n",
    "        # create bais vector of the shape [n_output]\n",
    "        b = tf.get_variable(\n",
    "                name='b',\n",
    "                shape=[n_output],\n",
    "                dtype=tf.float32,\n",
    "                initializer=tf.constant_initializer(0.0))\n",
    "        \n",
    "        # multiply the layer input and the weight matrix\n",
    "        # and add the bais\n",
    "        h = tf.nn.bias_add(\n",
    "                name='h',\n",
    "                value=tf.matmul(current_input, W),\n",
    "                bias=b)\n",
    "        \n",
    "        # use an activation function (RELU) on the output and set it to the input for the next layer\n",
    "        current_input = tf.nn.relu(h)\n",
    "        \n",
    "        # update the input dimensions with the current layer output\n",
    "        n_input = n_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the current_input of the last layer is Y\n",
    "Y = current_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define cost function\n",
    "Define the training signal.\n",
    "This will be a cost function to measure the success of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# measure average difference across pixels\n",
    "pixel_cost = tf.reduce_mean(tf.squared_difference(X, Y), 1)\n",
    "\n",
    "# measure mean across batches\n",
    "cost = tf.reduce_mean(pixel_cost)\n",
    "\n",
    "# use an Adam optimizer for training which tries to minimize cost\n",
    "learning_rate = 0.001\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a session to use the graph\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train by running n batches for n epochs\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "for epoch_i in range(n_epochs):\n",
    "    for batch_i in range(n_batches):\n",
    "        # get batch\n",
    "        batch_X = get_batch(batch_size, reshaped_images)\n",
    "\n",
    "        # preprocess batch\n",
    "        preprocessed_batch = preprocess(batch_X, mean_image, std_dev_image)\n",
    "        \n",
    "        # train\n",
    "        sess.run(optimizer, feed_dict={X: preprocessed_batch})\n",
    "\n",
    "        # show cost per epoch\n",
    "        print(epoch_i, batch_i, sess.run(cost, feed_dict={X: preprocessed_batch}))\n",
    "\n",
    "    # preprocess the test images\n",
    "    preprocessed_test_images = preprocess(test_images, mean_image, std_dev_image)\n",
    "\n",
    "    # reconstruct the test images\n",
    "    reconstructed_test_images = sess.run(Y, feed_dict={X: preprocessed_test_images})\n",
    "\n",
    "    # deprocess the test images\n",
    "    deprocessed_test_images = deprocess(reconstructed_test_images, mean_image, std_dev_image)\n",
    "    \n",
    "    # reshape them to the original shape and type\n",
    "    reshaped_deprocessed_test_images = deprocessed_test_images.reshape(-1, resize_dim, resize_dim)\n",
    "\n",
    "    # plot them results for this epoch\n",
    "    show_images(reshaped_deprocessed_test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate a new image\n",
    "Use the trained model to generate a new image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of images to generate\n",
    "n_new_images = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate using random numbers\n",
    "np.random.RandomState(seed=0)\n",
    "new_images = np.random.rand(n_new_images, resize_dim, resize_dim)\n",
    "\n",
    "# flatten the images\n",
    "reshaped_new_images = new_images.reshape(-1, n_features)\n",
    "\n",
    "# view the image\n",
    "show_images(new_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruct without normalizing against training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct the example images\n",
    "reconstructed_images = sess.run(Y, feed_dict={X: reshaped_new_images})\n",
    "\n",
    "# reshape them to the original shape and type\n",
    "reshaped_reconstructed_images = (reconstructed_images).reshape(-1, resize_dim, resize_dim)\n",
    "\n",
    "# plot them\n",
    "show_images(reshaped_reconstructed_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruct with normalizing against training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess batch\n",
    "preprocessed_new_images = preprocess(reshaped_new_images, mean_image, std_dev_image)\n",
    "\n",
    "# reconstruct the example images\n",
    "reconstructed_images = sess.run(Y, feed_dict={X: preprocessed_new_images})\n",
    "\n",
    "# deprocess the test images\n",
    "deprocessed_new_images = deprocess(reconstructed_images, mean_image, std_dev_image)\n",
    "    \n",
    "# reshape them to the original shape and type\n",
    "reshaped_deprocessed_images = deprocessed_new_images.reshape(-1, resize_dim, resize_dim)\n",
    "\n",
    "# plot them\n",
    "show_images(reshaped_deprocessed_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Transfer style to an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab an image\n",
    "transfer_image = data.astronaut()\n",
    "\n",
    "# resize the image and put it into gray scale\n",
    "resized_transfer_image = gray_scale_resize(transfer_image, resize_dim)\n",
    "\n",
    "# flatten the image\n",
    "reshaped_transfer_image = resized_transfer_image.reshape(-1, n_features)\n",
    "\n",
    "# display an image\n",
    "show_image(resized_transfer_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruct without normalizing against training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct the example images\n",
    "reconstructed_transfer_image = sess.run(Y, feed_dict={X: reshaped_transfer_image})\n",
    "\n",
    "# reshape them to the original shape and type\n",
    "reshaped_reconstructed_transfer_image = reconstructed_transfer_image.reshape(resize_dim, resize_dim)\n",
    "\n",
    "# plot them\n",
    "show_image(reshaped_reconstructed_transfer_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruct with normalizing against training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess batch\n",
    "preprocessed_transfer_images = preprocess(reshaped_transfer_image, mean_image, std_dev_image)\n",
    "\n",
    "# reconstruct the example images\n",
    "reconstructed_transfer_image = sess.run(Y, feed_dict={X: preprocessed_transfer_images})\n",
    "\n",
    "# deprocess the test images\n",
    "deprocessed_transfer_images = deprocess(reconstructed_transfer_image, mean_image, std_dev_image)\n",
    "  \n",
    "# reshape them to the original shape and type\n",
    "reshaped_deprocessed_transfer_image = deprocessed_transfer_images.reshape(resize_dim, resize_dim)\n",
    "\n",
    "# plot them\n",
    "show_image(reshaped_deprocessed_transfer_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Examine results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This does a much better job reconstructing the images than the PCA model. It still doesn't work so theres are few things we can do:\n",
    "    - get more data\n",
    "    - get better data\n",
    "    \n",
    "    \n",
    "Lets explore a convolutional autoencoder first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
