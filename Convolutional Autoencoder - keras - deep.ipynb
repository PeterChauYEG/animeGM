{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AnimeGM - Autoencoder - Keras\n",
    "GOAL: Generate new anime-style images\n",
    "\n",
    "View model: `$ tensorboard --logdir=autoencoder`\n",
    "\n",
    "Methodology:\n",
    "1. Build a dataset of images suitable for out needs\n",
    "2. Build a generative model.\n",
    "3. Train the model\n",
    "4. Generate a new image with random numbers\n",
    "5. Transfer style to a photo\n",
    "6. Examine results\n",
    "\n",
    "It seems that this is our best model yet. A few notes:\n",
    "- the larger the resized image, the better.\n",
    "- more data is good\n",
    "- about 100 epochs is good but we can use more.\n",
    "- best so far is using a batch size of 100\n",
    "- a lost of 0.37 is the best we can do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Build a dataset\n",
    "Pull in an existing dataset and modify it for my needs.\n",
    "\n",
    "Lets start with the danbooru 2017 anime image dataset. Now this dataset is huge. So we are only going to use 1 torrent of the SFW subset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import misc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import color\n",
    "import seaborn as sns; sns.set()\n",
    "from skimage.transform import resize\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from skimage import data\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.ops import reset_default_graph\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf image preprocessing\n",
    "# load, decoded and resize\n",
    "def parse_image(image_path):\n",
    "    image_string = tf.read_file(image_path)\n",
    "    \n",
    "    # decode\n",
    "    image = tf.image.decode_jpeg(image_string, channels=3)\n",
    "    \n",
    "    # check for 1 channel\n",
    "    # if so, grayscale\n",
    "    if (n_channels == 1):\n",
    "        image = tf.image.rgb_to_grayscale(image)\n",
    "        \n",
    "    # resize the image\n",
    "    image = tf.image.resize_images(image, [resize_dim, resize_dim])\n",
    "    \n",
    "    # feature normalize the image\n",
    "    image = tf.divide(image, 255)\n",
    "    \n",
    "    # check if we want the image flattened\n",
    "    # if so, flatten the image\n",
    "    if flatten == True:\n",
    "        image = tf.reshape(image, [-1])\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_image(image):\n",
    "    # check for 1 channel\n",
    "    # if so, grayscale\n",
    "    if (n_channels == 1):\n",
    "        image = image.reshape((resize_dim, resize_dim))\n",
    "    else:\n",
    "        image = image.reshape((resize_dim, resize_dim, n_channels))\n",
    "\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_images(images, figsize=(10, 10)):\n",
    "   # get the number of images\n",
    "    n_images = images.shape[0]\n",
    "    \n",
    "    if n_images == 1:\n",
    "        show_image(images[0])\n",
    "        return\n",
    "    \n",
    "    # get the square root of the number of images\n",
    "    squareroot = int(np.ceil(np.sqrt(n_images)))\n",
    "    \n",
    "    fig, ax = plt.subplots(squareroot, squareroot, figsize=figsize,\n",
    "                           subplot_kw=dict(xticks=[], yticks=[]))\n",
    "    fig.subplots_adjust(hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for i, axi in enumerate(ax.flat):\n",
    "        # exit if the index of subplots is greater than amount of images\n",
    "        if i > n_images - 1:\n",
    "            return\n",
    "        \n",
    "        image = images[i]\n",
    "        \n",
    "        # check for 1 channel\n",
    "        # if so, grayscale\n",
    "        if (n_channels == 1):\n",
    "            image = image.reshape((resize_dim, resize_dim))\n",
    "        else:\n",
    "            image = image.reshape((resize_dim, resize_dim, n_channels))\n",
    "\n",
    "        im = axi.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir_name = 'danbooru-small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 100\n",
    "n_test = 10\n",
    "\n",
    "resize_dim = 64\n",
    "n_channels = 1\n",
    "n_features = resize_dim * resize_dim * n_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters~~~~\n",
    "batch_size = 10\n",
    "n_batches = int(n_train / batch_size)\n",
    "n_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = False\n",
    "log_dir = '/Users/Admin/data-science/animeGM/autoencoder'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get filenames and join paths as np array\n",
    "base_filenames = listdir(dir_name)\n",
    "filename_paths = [join(dir_name, base_filename) for base_filename in base_filenames]\n",
    "filename_paths = np.array(filename_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create paths for train and test\n",
    "train_paths = filename_paths[:-n_test][:n_train]\n",
    "test_paths = filename_paths[:n_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the current graph and start over\n",
    "reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset from the paths\n",
    "image_paths = tf.placeholder(tf.string, shape=[None])\n",
    "dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n",
    "dataset = dataset.map(parse_image)\n",
    "dataset = dataset.shuffle(buffer_size=n_train)\n",
    "dataset = dataset.batch(batch_size)\n",
    "dataset = dataset.repeat()\n",
    "\n",
    "# iterators\n",
    "iter = dataset.make_initializable_iterator()\n",
    "next_ele = iter.get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build a generative model\n",
    "Lets build an autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import Conv2D, Dense, Flatten, Input, MaxPooling2D, Reshape, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-04060df8d506>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# input placeholder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresize_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresize_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_channels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# encoded the input with convolutions and pooling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'encoder_0'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Input' is not defined"
     ]
    }
   ],
   "source": [
    "# input placeholder\n",
    "inputs = Input(shape=(resize_dim, resize_dim, n_channels))\n",
    "\n",
    "# encoded the input with convolutions and pooling\n",
    "x = Conv2D(16, (3, 3), activation='relu', name='encoder_0', padding='same')(inputs)\n",
    "x = MaxPooling2D((2, 2), padding='same', name='pool_0')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', name='encoder_1', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same', name='pool_1')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', name='encoder_2', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same', name='pool_2')(x)\n",
    "\n",
    "# decoded the compression and upsampling\n",
    "x = Conv2D(8, (3, 3), activation='relu', name='decoder_0', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2), name='upsample_0')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', name='decoder_1', padding='same')(x)\n",
    "x = UpSampling2D((2, 2), name='upsample_1')(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', name='decoder_2', padding='same')(x)\n",
    "x = UpSampling2D((2, 2), name='upsample_2')(x)\n",
    "decoded = Conv2D(n_channels, (3, 3), activation='sigmoid', name='decoder_3', padding='same')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model maps inputs to its reconstructions\n",
    "autoencoder = Model(inputs, decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model with cost and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder.compile(loss='binary_crossentropy', \n",
    "              optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a session to use the graph\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    while 1:\n",
    "        batch = sess.run(next_ele)\n",
    "        yield batch, batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 5s 483ms/step - loss: 0.6929\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 3s 301ms/step - loss: 0.6915\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 3s 301ms/step - loss: 0.6900\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.6858\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.6706\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 4s 367ms/step - loss: 0.6482\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 4s 362ms/step - loss: 0.6435\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.6197\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.6146\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 3s 315ms/step - loss: 0.6018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26939421320>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize an iterator over a training dataset.\n",
    "sess.run(iter.initializer, feed_dict={image_paths: train_paths})\n",
    "\n",
    "batch_generator = generator()\n",
    "    \n",
    "# train\n",
    "autoencoder.fit_generator(batch_generator, \n",
    "                          steps_per_epoch=n_batches,\n",
    "                          epochs=n_epochs,\n",
    "                          callbacks=[TensorBoard(log_dir=log_dir)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an iterator over a testing dataset.\n",
    "sess.run(iter.initializer, feed_dict={image_paths: test_paths})\n",
    "    \n",
    "# get batch\n",
    "test_batch_X = sess.run(next_ele)\n",
    "\n",
    "# show the test images\n",
    "show_images(test_batch_X)\n",
    "\n",
    "# create reconstructions\n",
    "reconstructions = autoencoder.predict(test_batch_X)\n",
    "\n",
    "# show the reconstructioned test images\n",
    "show_images(reconstructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "### Test 1\n",
    "image_size =  32 x 32  \n",
    "n_channels = 1  \n",
    "n_epochs = 100  \n",
    "batch_size = 100  \n",
    "lost = 0.37  \n",
    "NOTE: too pixalated and noisy\n",
    "\n",
    "### Test 2\n",
    "image_size =  64 x 64  \n",
    "n_channels = 1  \n",
    "n_epochs = 40  \n",
    "batch_size = 100  \n",
    "lost = 0.3654  \n",
    "NOTE: The larger image size helps use get closer to the actual images. They are still blurry\n",
    "\n",
    "### Test 3\n",
    "n_conv_layers = 4\n",
    "image_size =  64 x 64  \n",
    "n_channels = 3  \n",
    "n_epochs = 70  \n",
    "batch_size = 100  \n",
    "lost = 0.5266  \n",
    "NOTE: bad\n",
    "\n",
    "### Test 4\n",
    "n_conv_layers = 4\n",
    "image_size =  64 x 64  \n",
    "n_channels = 3  \n",
    "n_epochs = 50  \n",
    "batch_size = 100  \n",
    "lost = 0.6194\n",
    "NOTE: bad\n",
    "\n",
    "### Test 5\n",
    "n_conv_layers = 4\n",
    "image_size =  64 x 64  \n",
    "n_channels = 1  \n",
    "n_epochs = 50  \n",
    "batch_size = 100  \n",
    "lost = 0.6732\n",
    "NOTE: bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
