{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AnimeGM\n",
    "GOAL: Generate new anime-style images\n",
    "    \n",
    "Methodology:\n",
    "1. Build a dataset of images suitable for out needs. There should be at least 1000 images of the same size 28x28?\n",
    "2. Build a generative model.\n",
    "3. Train the model\n",
    "4. Generate a new image with random numbers\n",
    "5. Apply the this model to a real image\n",
    "6. Examine results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Build a dataset\n",
    "Pull in an existing dataset and modify it for my needs.\n",
    "\n",
    "Lets start with the danbooru 2017 anime image dataset. Now this dataset is huge. So we are only going to use 1 torrent of the SFW subset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Load 1 image from the danbooru dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import misc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import color\n",
    "import seaborn as sns; sns.set()\n",
    "from skimage.transform import resize\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gray_scale_resize(image, reshape_dim):\n",
    "    # convert image to grayscale\n",
    "    # same computation while we experiment\n",
    "    gray_image = color.rgb2gray(image)\n",
    "    \n",
    "    # Resize the image down to 128x128\n",
    "    resized_image = resize(gray_image, (reshape_dim, reshape_dim))\n",
    "    \n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_image(image):\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reshape_dim = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read an image\n",
    "image = misc.imread('danbooru-small/1800.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_image = gray_scale_resize(image, reshape_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display an image\n",
    "show_image(resized_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load 2 images from the danbooru dataset\n",
    "We've loaded 1 image of the dataset but lets load 2 as a pandas dataframe so that we can work with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_images(paths_list, n_images, reshape_dim):\n",
    "    # slice paths list to the amount we want\n",
    "    slice_paths_list = paths_list[:n_images]\n",
    "\n",
    "    # create an array for images\n",
    "    images = np.zeros((n_images, reshape_dim, reshape_dim), dtype=np.float32)\n",
    "        \n",
    "    for i, image_path in enumerate(slice_paths_list): \n",
    "        # read image\n",
    "        image = misc.imread(join(path, image_path))\n",
    "\n",
    "        # rescale image\n",
    "        images[i] = gray_scale_resize(image, reshape_dim)\n",
    "        \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_image(images, figsize=(10, 10)):\n",
    "    # get the number of images\n",
    "    n_images = images.shape[0]\n",
    "    # get the square root of the number of images\n",
    "    squareroot = int(np.ceil(np.sqrt(n_images)))\n",
    "    \n",
    "    fig, ax = plt.subplots(squareroot, squareroot, figsize=figsize,\n",
    "                           subplot_kw=dict(xticks=[], yticks=[]))\n",
    "    fig.subplots_adjust(hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for i, axi in enumerate(ax.flat):\n",
    "        # exit if the index of subplots is greater than amount of images\n",
    "        if i >= n_images:\n",
    "            return\n",
    "        im = axi.imshow(images[i], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'danbooru-small'\n",
    "paths_list = listdir(path)\n",
    "n_images = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images\n",
    "images = load_images(paths_list, n_images, reshape_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the images of the dataset\n",
    "plot_image(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. Build a generative model\n",
    "We will perform Principal Component Analysis to preserve 99% of the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the images\n",
    "reshaped_images = images.reshape(-1, reshape_dim*reshape_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fit the images and determine the number of components to use\n",
    "pca = PCA().fit(reshaped_images)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimal_n_components = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the PCA with the optimal number of components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=optimal_n_components, whiten=True)\n",
    "pca.fit(reshaped_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate a new image\n",
    "Use the trained PCA to generate a new projected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_new_images = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a random image of the shape needed to feed the PCA inverse transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.RandomState(seed=0)\n",
    "images_new = np.random.rand(n_new_images, optimal_n_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the inverse transform of the PCA object to construct the new image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformed_images_new = pca.inverse_transform(images_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformed_images_new_reshaped = transformed_images_new.reshape(n_new_images, reshape_dim, reshape_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image(transformed_images_new_reshaped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Apply model to a real image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab an image\n",
    "test_image = data.astronaut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_test_image = gray_scale_resize(test_image, reshape_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display an image\n",
    "show_image(resized_test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the image\n",
    "reshaped_test_image = resized_test_image.reshape(-1, reshape_dim*reshape_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the image with PCA\n",
    "transform_test_image = pca.transform(reshaped_test_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the inverse transform of the PCA object to construct the new image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regenerated_test_image = pca.inverse_transform(transform_test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regenerated_test_image_reshaped = regenerated_test_image.reshape(reshape_dim, reshape_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(regenerated_test_image_reshaped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 6. Examine results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We seem to need more images for PCA and aren't able to hit the maxima. We'll definately need to increase the number of images used.\n",
    "\n",
    "Although we can generate images, aren't very meaningful. Lets attempt to take an image of a person's face, and feed that into PCA?\n",
    "\n",
    "**Results**\n",
    "64 dim; 100 samples; 8 n_components = not good  \n",
    "128 dim; 100 samples; 8 n_components = clearer  \n",
    "128 dim; 100 samples; 80 n_components = more detailed  \n",
    "128 dim; 200 samples; 80 n_components = blobbly  \n",
    "128 dim; 200 samples; 175 n_components = starting to resample something...  \n",
    "128 dim; 300 samples; 175 n_components = the major features of the original image can be seen, but it's blobbly  \n",
    "128 dim; 300 samples; 250 n_components = clearer but still mangled  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
